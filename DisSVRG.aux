\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\emailauthor{ywming@nudt.edu.cn}{Yuewei Ming\corref {mycorrespondingauthor}}
\Newlabel{mycorrespondingauthor}{1}
\Newlabel{mymainaddress}{a}
\Newlabel{mysecondaryaddress}{b}
\citation{Coates2011An}
\citation{dahl2012context}
\citation{collobert2008unified}
\citation{Vidaurre:2013cu,Gnecco2015Learning,Cucker2002On}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\newlabel{introduction}{{1}{2}{Introduction}{section.1}{}}
\newlabel{equa_loss_minimization}{{1}{2}{Introduction}{equation.1.1}{}}
\citation{Dean:2012wx,Li:2014tt,Xing:2015ib}
\citation{Xing:2015ib}
\citation{Johnson:9MAvkbgy,Zhao:SZfxEHHg,Reddi:2015vj}
\citation{Dean:2012wx,Li:2014tt,Xing:2015ib}
\citation{Cavalcante:2009il}
\citation{Li:2014tt}
\citation{Xing:2015ib}
\citation{Zhang:2015tp}
\citation{Harlap:2016ia}
\citation{Li:2014jg}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{5}{section.2}}
\newlabel{related_work}{{2}{5}{Related work}{section.2}{}}
\citation{Johnson:9MAvkbgy}
\citation{Zhao:SZfxEHHg,Reddi:2015vj,Mania:2015wa,lian2015asynchronous,Pan:2016wx}
\citation{Defazio:2014vu}
\citation{Richtarik:2013te}
\citation{Allen2015Improved}
\citation{Xiao:2014vw}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The highlight notations}}{7}{table.1}}
\newlabel{tab:notations}{{1}{7}{The highlight notations}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Preliminaries}{7}{section.3}}
\newlabel{sect_preliminary}{{3}{7}{Preliminaries}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Notations}{7}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Parameter server and data parallelism}{7}{subsection.3.2}}
\newlabel{parameter server}{{3.2}{7}{Parameter server and data parallelism}{subsection.3.2}{}}
\citation{ho2013more}
\citation{xing2015petuum}
\citation{ho2013more}
\citation{dai2015high}
\newlabel{figure_data_parallelism}{{3.2}{8}{Parameter server and data parallelism}{equation.3.3}{}}
\newlabel{figure_data_parallelism_on_PS}{{1(a)}{8}{Subfigure 1(a)}{subfigure.1.1}{}}
\newlabel{sub@figure_data_parallelism_on_PS}{{(a)}{8}{Subfigure 1(a)\relax }{subfigure.1.1}{}}
\newlabel{figure_PS_topology}{{1(b)}{8}{Subfigure 1(b)}{subfigure.1.2}{}}
\newlabel{sub@figure_PS_topology}{{(b)}{8}{Subfigure 1(b)\relax }{subfigure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of data parallelism and parameter server topology}}{8}{figure.1}}
\newlabel{figure_data_parallelism}{{1}{8}{Illustration of data parallelism and parameter server topology}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Variance reduced SGD}{9}{subsection.3.3}}
\newlabel{equa_vr_gradient}{{4}{9}{Variance reduced SGD}{equation.3.4}{}}
\newlabel{equa_vr_gradient}{{5}{9}{Variance reduced SGD}{equation.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}System implementation}{9}{section.4}}
\newlabel{implementation}{{4}{9}{System implementation}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Overview}{9}{subsection.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces DisSVRG}}{10}{algorithm.1}}
\newlabel{algorithm_dis_svrg}{{1}{10}{Overview}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Distributed implementation}{11}{subsection.4.2}}
\citation{Johnson:9MAvkbgy}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Server}}{12}{algorithm.2}}
\newlabel{algorithm_dis_svrg_server}{{2}{12}{Distributed implementation}{algorithm.2}{}}
\newlabel{standard_sgd}{{6}{12}{Distributed implementation}{equation.4.6}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Worker}}{13}{algorithm.3}}
\newlabel{algorithm_dis_svrg_worker}{{3}{13}{Distributed implementation}{algorithm.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Optimization of DisSVRG}{13}{section.5}}
\newlabel{optimization_sgd}{{5}{13}{Optimization of DisSVRG}{section.5}{}}
\citation{Johnson:9MAvkbgy}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Learning rate with an acceleration factor}{14}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The learning rate with the acceleration factor makes DisSVRG converge fast significantly.}}{15}{figure.2}}
\newlabel{figure_evaluation_accelerated_factor}{{2}{15}{The learning rate with the acceleration factor makes DisSVRG converge fast significantly}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Adaptive sampling strategy}{15}{subsection.5.2}}
\citation{Xing:2015ib}
\citation{Yuan:2015ka}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{16}{section.6}}
\newlabel{discussion}{{6}{16}{Discussion}{section.6}{}}
\newlabel{figure_evaluation_random_strategy_accelerated_factor}{{3(a)}{17}{Subfigure 3(a)}{subfigure.3.1}{}}
\newlabel{sub@figure_evaluation_random_strategy_accelerated_factor}{{(a)}{17}{Subfigure 3(a)\relax }{subfigure.3.1}{}}
\newlabel{figure_evaluation_random_strategy_wait_time}{{3(b)}{17}{Subfigure 3(b)}{subfigure.3.2}{}}
\newlabel{sub@figure_evaluation_random_strategy_wait_time}{{(b)}{17}{Subfigure 3(b)\relax }{subfigure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A large $m$ leads to a fast convergence for DisSVRG, and reduces much wait time during iterations.}}{17}{figure.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{17}{figure.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{17}{figure.3}}
\newlabel{figure_evaluation_random_strategy}{{3}{17}{A large $m$ leads to a fast convergence for DisSVRG, and reduces much wait time during iterations}{figure.3}{}}
\citation{Zhang:2015tp}
\citation{Zhang:2015tp}
\citation{2015_dai_high_performance_ml,Li:2014uy,Dai:2013vj}
\citation{Zhang:2015tp}
\citation{Yuan:2015ka}
\@writefile{toc}{\contentsline {section}{\numberline {7}Performance evaluation}{19}{section.7}}
\newlabel{performance_evaluation}{{7}{19}{Performance evaluation}{section.7}{}}
\newlabel{regression}{{11}{19}{Performance evaluation}{equation.7.11}{}}
\newlabel{classification}{{12}{19}{Performance evaluation}{equation.7.12}{}}
\citation{Xing:2015ib}
\citation{Zhang:2015tp}
\citation{Zhang:2015tp}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Convergence}{20}{subsection.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The performance of the convergence is compared by using $32$ computing nodes.}}{21}{figure.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\emph {YearPredictionMSD}}}}{21}{figure.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\emph {dna}}}}{21}{figure.4}}
\newlabel{figure_evaluation1_convergence}{{4}{21}{The performance of the convergence is compared by using $32$ computing nodes}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Speedup}{21}{subsection.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces DisSVRG obtains almost linear speedup when varying the number of workers.}}{22}{figure.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\emph {YearPredictionMSD}}}}{22}{figure.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\emph {dna}}}}{22}{figure.5}}
\newlabel{figure_evaluation2_speedup}{{5}{22}{DisSVRG obtains almost linear speedup when varying the number of workers}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Wait time}{22}{subsection.7.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The time consumption is compared by varying the delay $\tau $ for $128$ workers.}}{23}{figure.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\emph {YearPredictionMSD}}}}{23}{figure.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\emph {dna}}}}{23}{figure.6}}
\newlabel{figure_evaluation3_delay}{{6}{23}{The time consumption is compared by varying the delay $\tau $ for $128$ workers}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{23}{section.8}}
\newlabel{conclusion}{{8}{23}{Conclusion}{section.8}{}}
\bibstyle{elsarticle-num}
\bibdata{reference}
\bibcite{Coates2011An}{{1}{}{{}}{{}}}
\bibcite{dahl2012context}{{2}{}{{}}{{}}}
\bibcite{collobert2008unified}{{3}{}{{}}{{}}}
\bibcite{Vidaurre:2013cu}{{4}{}{{}}{{}}}
\bibcite{Gnecco2015Learning}{{5}{}{{}}{{}}}
\bibcite{Cucker2002On}{{6}{}{{}}{{}}}
\bibcite{Dean:2012wx}{{7}{}{{}}{{}}}
\bibcite{Li:2014tt}{{8}{}{{}}{{}}}
\bibcite{Xing:2015ib}{{9}{}{{}}{{}}}
\bibcite{Johnson:9MAvkbgy}{{10}{}{{}}{{}}}
\bibcite{Zhao:SZfxEHHg}{{11}{}{{}}{{}}}
\bibcite{Reddi:2015vj}{{12}{}{{}}{{}}}
\bibcite{Cavalcante:2009il}{{13}{}{{}}{{}}}
\bibcite{Zhang:2015tp}{{14}{}{{}}{{}}}
\bibcite{Harlap:2016ia}{{15}{}{{}}{{}}}
\bibcite{Li:2014jg}{{16}{}{{}}{{}}}
\bibcite{Mania:2015wa}{{17}{}{{}}{{}}}
\bibcite{lian2015asynchronous}{{18}{}{{}}{{}}}
\bibcite{Pan:2016wx}{{19}{}{{}}{{}}}
\bibcite{Defazio:2014vu}{{20}{}{{}}{{}}}
\bibcite{Richtarik:2013te}{{21}{}{{}}{{}}}
\bibcite{Allen2015Improved}{{22}{}{{}}{{}}}
\bibcite{Xiao:2014vw}{{23}{}{{}}{{}}}
\bibcite{ho2013more}{{24}{}{{}}{{}}}
\bibcite{xing2015petuum}{{25}{}{{}}{{}}}
\bibcite{dai2015high}{{26}{}{{}}{{}}}
\bibcite{Yuan:2015ka}{{27}{}{{}}{{}}}
\bibcite{2015_dai_high_performance_ml}{{28}{}{{}}{{}}}
\bibcite{Li:2014uy}{{29}{}{{}}{{}}}
\bibcite{Dai:2013vj}{{30}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
